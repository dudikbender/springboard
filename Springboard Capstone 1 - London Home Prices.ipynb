{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intro to the problem that is being addressed.\n",
    "## Looking at residential home prices paid data from UK Data\n",
    "## Predicting home price paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the relevant python packages\n",
    "\n",
    "## Core packages for data wrangling, analysis, and charting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from collections import Counter\n",
    "\n",
    "## Mapping packages for presentation and geocoding\n",
    "import folium\n",
    "#from folium.features import Features, CustomIcon\n",
    "import geopandas\n",
    "import gmaps #Google Maps python package\n",
    "import branca\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "## Statistics and machine learning packages\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Introduce the dataset and provide a url\n",
    "\n",
    "## import the whole dataset for 2018\n",
    "## Data does not have column headers, so we set these up to add custom column names\n",
    "column_labels = ['transaction_ID', 'price', 'transfer_date', 'postcode','property_type', \n",
    "              'new_build','duration', 'PAON', 'SAON', 'street', 'locality', 'town_city', \n",
    "              'district', 'county', 'PPD_category_type', 'record_status']\n",
    "\n",
    "## Read in the UK Housing Prices Paid 2018 dataset\n",
    "## requires chunking (importing it in pieces) as it is a large file\n",
    "df_chunk = pd.read_csv(\"/Users/user/Desktop/Datasets/pp-2018.csv\", names=column_labels,\n",
    "                      iterator=True, chunksize=10000)\n",
    "\n",
    "## concatenate the chunks into one DataFrame \n",
    "chunk_list = []  # append each chunk here \n",
    "\n",
    "# Each chunk is in df format\n",
    "for chunk in df_chunk:      \n",
    "    # Once the data filtering is done, append the chunk to list\n",
    "    chunk_list.append(chunk)\n",
    "    \n",
    "# concat the list into dataframe \n",
    "df = pd.concat(chunk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter down to London only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will create a couple new columns, which will help in our later analysis.\n",
    "## These will be a trimmed postcode that correlates to postcode areas, as well as \n",
    "## month and year separated out from date column.\n",
    "\n",
    "## Trim the postcode column down to the first set of characters (removing last 3)\n",
    "df['postcode_area'] = [str(x)[:-4] for x in df.postcode]\n",
    "\n",
    "## Convert transfer date to DateTime object\n",
    "df['transfer_date'] = pd.to_datetime(df.transfer_date)\n",
    "\n",
    "## Add month and year columns\n",
    "df['month'] = df['transfer_date'].dt.month\n",
    "df['year'] = df['transfer_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_type_dict = {'D': 'Detached',\n",
    "                 'S': 'Semi-detached',\n",
    "                 'F': 'Flat',\n",
    "                 'T': 'Terraced',\n",
    "                 'O': 'Other'}\n",
    "\n",
    "new_build_dict = {'N': 'Old',\n",
    "                 'Y': 'New'}\n",
    "\n",
    "duration_dict = {'F': 'Freehold',\n",
    "                 'L': 'Leasehold'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add a conditional to this conversion so that if this notebook is run multiple times we won't get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df['property_type'][0]) == 1:\n",
    "    df['property_type'] = df['property_type'].map(prop_type_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## comment out to prevent future errors // \n",
    "if len(df['new_build'][0]) == 1:\n",
    "    df['new_build'] = df['new_build'].map(new_build_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## comment out to prevent future errors // \n",
    "if len(df['duration'][0]) == 1:\n",
    "    df['duration'] = df['duration'].map(duration_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to compare the London buroughs\n",
    "\n",
    "def burough_comparison(burough1, burough2):\n",
    "    burough01 = df[df['county'] == burough1.upper()]\n",
    "    burough02 = df[df['county'] == burough2.upper()]\n",
    "    \n",
    "    if (len(burough0) == 0) or (len(burough02)) == 0:\n",
    "        print('One or both of your selected boroughs is not available or not spelled correctly')\n",
    "    \n",
    "    else:    \n",
    "        plt.boxplot([burough0.price, burough02.price],\n",
    "                         labels=[county1, county2], \n",
    "                         autorange=True, widths=0.15, vert=True)\n",
    "        plt.title('Distribution of Prices Paid - 2018')\n",
    "        plt.xlabel('Prices paid distribution')\n",
    "        plt.ylabel('Counties')\n",
    "        plt.show()\n",
    "    \n",
    "county_comparison('Greater London', 'Greater Manchester')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add in the population density information to create a scatter plot of prices to density\n",
    "## Data source: Nomis UK population database of all postcode areas and population density from\n",
    "## 2011 - ONS Crown Copyright Reserved [from Nomis on 24 October 2019]\n",
    "pop_density = pd.read_csv('UK_pop_density_postcodes.csv')[8:]\n",
    "density_columns = ['long_code', 'postcode_area', 'population_density']\n",
    "pop_density.columns = density_columns\n",
    "pop_density = pop_density.drop(columns='long_code')\n",
    "pop_density.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the population density data to the prices paid dataset by merging the tables\n",
    "## Used an if-statement to prevent multiple merges.\n",
    "if 'population_density' not in df.columns:\n",
    "    df = df.merge(pop_density, how='left', on='postcode_area')\n",
    "\n",
    "df[df['postcode_area'] == 'N4'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add additional datasets that will be used - London boroughs and London wards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## geotag the London data\n",
    "#1. geo = Nominatim(address, user_agent='my-application', country_bias='UK')\n",
    "#geo\n",
    "#2.  Or use the requests package to make API call with address details to Nominatim API\n",
    "#3. geopandas geocoding via geopy [ geopandas.tools.geocode(x) for x in dataset ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map the London dataset\n",
    "\n",
    "## Add the polygon boroughs and wards as optional layers\n",
    "## Add a heatmap of the properties as optional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a function that adds the number of nearby sales as an additional attribute to the homes dataset\n",
    "## for x in len(range(dataset)):\n",
    "#        geopandas.overlay(how='intersection')\n",
    "    \n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "polys1 = geopandas.GeoSeries([Polygon([(0,0), (2,0), (2,2), (0,2)]),\n",
    "                               Polygon([(2,2), (4,2), (4,4), (2,4)])])\n",
    "\n",
    "polys2 = geopandas.GeoSeries([Polygon([(1,1), (3,1), (3,3), (1,3)]),\n",
    "                               Polygon([(3,3), (5,3), (5,5), (3,5)])])\n",
    "\n",
    "df1 = geopandas.GeoDataFrame({'geometry': polys1, 'df1':[1,2]})\n",
    "\n",
    "df2 = geopandas.GeoDataFrame({'geometry': polys2, 'df2':[1,2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df1.plot(color='red');\n",
    "\n",
    "df2.plot(ax=ax, color='green', alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_union = geopandas.overlay(df1, df2, how='union') # or intersection, symmetric_difference, difference\n",
    "ax = res_union.plot(alpha=0.8, cmap='tab10')\n",
    "\n",
    "df1.plot(ax=ax, facecolor='none', edgecolor='k');\n",
    "\n",
    "df2.plot(ax=ax, facecolor='none', edgecolor='k');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prep dataset as earlier version for Decision Tree and Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Present the results of the prediction with a few different scipy algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For predictive modelling, first we will preprocess the data to ensure it can by properly read by the scikit-learn packge. This involves converting ordinal (categorical) data into numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new dataframe using the function created above to capture the \n",
    "## top 10 cities by sales counts\n",
    "\n",
    "df_ten = df[df['town_city'].isin(top_cities(1, 10).iloc[:,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_ten[['property_type', 'new_build', 'town_city']]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "x_encoded = enc.fit_transform(test_df)\n",
    "\n",
    "x_encoded = pd.DataFrame(x_encoded)\n",
    "\n",
    "x_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_type = df_ten['new_build']\n",
    "prop_type = df_ten['property_type']\n",
    "cityID = df_ten['town_city']\n",
    "\n",
    "xencode = LabelEncoder()\n",
    "build_type = xencode.fit_transform(build_type)\n",
    "xkeys = xencode.classes_\n",
    "xkeys = list(xkeys)\n",
    "\n",
    "yencode = LabelEncoder()\n",
    "prop_type = yencode.fit_transform(prop_type)\n",
    "ykeys = yencode.classes_\n",
    "ykeys = list(ykeys)\n",
    "\n",
    "zencode = LabelEncoder()\n",
    "cityID = zencode.fit_transform(cityID)\n",
    "zkeys = zencode.classes_\n",
    "zkeys = list(zkeys)\n",
    "\n",
    "cols = xkeys + ykeys + zkeys\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_type = pd.DataFrame(build_type)\n",
    "prop_type = pd.DataFrame(prop_type)\n",
    "cityID = pd.DataFrame(cityID)\n",
    "\n",
    "data = pd.concat([build_type, prop_type, cityID], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ohe = OneHotEncoder().fit_transform(data).toarray()\n",
    "z = pd.DataFrame(data_ohe)\n",
    "\n",
    "z.columns = cols\n",
    "z['price'] = df_ten.price.reset_index().price\n",
    "z.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign the data to the scikit-learn packages, starting with Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor # Import Decision Tree Regressor\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "import locale\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, \"\")\n",
    "\n",
    "feature_cols = cols\n",
    "\n",
    "X = z[feature_cols] #features\n",
    "y = z.price #target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "reg = DecisionTreeRegressor()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "model = reg.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = np.random.uniform(low=0, high=len(df_ten))\n",
    "\n",
    "X_new = df_ten.iloc[int(rand)]\n",
    "\n",
    "# Model Accuracy, how often is the regressor correct?\n",
    "print(\"City X: %s\" % X_new.loc['town_city'])\n",
    "print('X: £{:,.2f}, Predicted: £{:,.2f}'.format(X_new[0], y_pred[X_new[0]]))\n",
    "print('Difference (£): {:+,.0f}'.format(X_new[0] - y_pred[0]))\n",
    "print('Difference Predicted (%): {:+.2f}%'.format(((y_pred[0] - X_new[0]) / X_new[0]) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
